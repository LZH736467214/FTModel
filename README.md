# é‡‘èæ¨ç†æ¨¡å‹åè®­ç»ƒé¡¹ç›®

åŸºäº **Fin-R1 è®ºæ–‡**çš„å®Œæ•´åè®­ç»ƒé“¾è·¯å®ç°ï¼Œæ¶µç›–æ•°æ®æ„å»ºã€SFTã€GRPO å¼ºåŒ–å­¦ä¹ ã€è¯„æµ‹ä¸éƒ¨ç½²å…¨æµç¨‹ã€‚

## âœ¨ é¡¹ç›®ç‰¹ç‚¹

- ğŸ—ï¸ **å®Œæ•´å·¥ç¨‹é“¾è·¯**ï¼šä»æ•°æ®æ„å»ºåˆ°æ¨¡å‹éƒ¨ç½²çš„å…¨æµç¨‹å®ç°
- ğŸ§  **ä¸‰æ¨¡å‹æ¶æ„**ï¼šTeacherï¼ˆè’¸é¦ï¼‰+ Judgeï¼ˆè¯„åˆ†ï¼‰+ Baseï¼ˆè®­ç»ƒï¼‰åˆ†å·¥æ˜ç¡®
- ğŸš€ **æœ¬åœ°éƒ¨ç½²ä¼˜å…ˆ**ï¼šæ‰€æœ‰æ¨¡å‹æœ¬åœ°è¿è¡Œï¼Œæ— éœ€è°ƒç”¨å¤–éƒ¨ API
- ğŸ“Š **Wandb é›†æˆ**ï¼šå¯è§†åŒ–ç›‘æ§è®­ç»ƒè¿‡ç¨‹
- ğŸ”¬ **æ¶ˆèå®éªŒ**ï¼šç§‘å­¦éªŒè¯æ¯ä¸ªç»„ä»¶çš„ä»·å€¼

## é¡¹ç›®èƒŒæ™¯

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªé‡‘èé¢†åŸŸçš„æ¨ç†å¢å¼ºæ¨¡å‹ï¼Œæ ¸å¿ƒæ€è·¯ï¼š

```text
åŸå§‹æ•°æ® â†’ æ•™å¸ˆè’¸é¦ â†’ åŒé‡è¿‡æ»¤ â†’ è®­ç»ƒæ•°æ®èµ„äº§
                                     â†“
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                             â†“               â†“
                           SFT            GRPO
                        (å­¦æ ¼å¼)        (æå‡†ç¡®ç‡)
                             â†“               â†“
                             â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â†“
                             è¯„æµ‹ â†’ éƒ¨ç½²
```

### æ¨¡å‹æ¶æ„

æœ¬é¡¹ç›®é‡‡ç”¨ä¸‰æ¨¡å‹æ¶æ„è®¾è®¡ï¼Œå®Œå…¨æœ¬åœ°éƒ¨ç½²ï¼š

| è§’è‰²        | æ¨¡å‹                        | ç”¨é€”                      | æ˜¾å­˜éœ€æ±‚    |
| ----------- | --------------------------- | ------------------------- | ----------- |
| **Teacher** | DeepSeek-R1-Distill-Qwen-7B | è’¸é¦é˜¶æ®µç”Ÿæˆ CoT          | ~8GB (4bit) |
| **Judge**   | Qwen2.5-7B-Instruct         | è¿‡æ»¤ã€GRPO è¯„åˆ†ã€è¯„æµ‹åˆ¤åˆ† | ~8GB (4bit) |
| **Base**    | Qwen2.5-1.5B-Instruct       | å¾…è®­ç»ƒçš„ç›®æ ‡å°æ¨¡å‹        | ~4GB (4bit) |

### å…³é”®æŠ€æœ¯å†³ç­–

| é—®é¢˜               | å†³ç­–                  | åŸå›                                  |
| ------------------ | --------------------- | ------------------------------------ |
| ä¸ºä»€ä¹ˆè¦æ•°æ®è’¸é¦ï¼Ÿ | ç”¨å¼ºæ¨¡å‹ç”Ÿæˆ CoT      | å°æ¨¡å‹ç¼ºä¹æ¨ç†èƒ½åŠ›                   |
| ä¸ºä»€ä¹ˆåŒé‡è¿‡æ»¤ï¼Ÿ   | è§„åˆ™è¿‡æ»¤ + Judge è¯„ä¼° | ç­”æ¡ˆæ˜¯ç¡¬çº¦æŸï¼Œæ¨ç†è´¨é‡éœ€ AI è¯„ä¼°     |
| ä¸ºä»€ä¹ˆå…ˆ SFTï¼Ÿ     | å­¦ä¹ è¾“å‡ºæ ¼å¼          | RL éœ€è¦ç¨³å®šçš„æ ¼å¼ä½œä¸ºåŸºç¡€            |
| ä¸ºä»€ä¹ˆç”¨ GRPOï¼Ÿ    | å¯éªŒè¯å¥–åŠ± + ç¨³å®šè®­ç»ƒ | é‡‘èåœºæ™¯éœ€è¦å®¢è§‚æ ‡å‡†                 |
| ä¸ºä»€ä¹ˆç”¨ vLLMï¼Ÿ    | é«˜æ€§èƒ½æ¨ç†            | PagedAttention + Continuous batching |

---

## é¡¹ç›®ç»“æ„

```text
FTModel/
â”œâ”€â”€ .gitignore                      # Git å¿½ç•¥é…ç½®
â”œâ”€â”€ README.md                       # é¡¹ç›®è¯´æ˜ï¼ˆæœ¬æ–‡ä»¶ï¼‰
â”œâ”€â”€ requirements.txt                # Python ä¾èµ–
â”œâ”€â”€ detect_plan.md                  # è¯¦ç»†æ‰§è¡Œè®¡åˆ’æ–‡æ¡£
â”‚
â”œâ”€â”€ configs/                        # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py                   # å…¨å±€é…ç½®ï¼ˆæ¨¡å‹ã€LoRAã€è®­ç»ƒå‚æ•°ï¼‰
â”‚
â”œâ”€â”€ scripts/                        # è„šæœ¬ç›®å½•ï¼ˆæŒ‰æ‰§è¡Œé¡ºåºç¼–å·ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ 1_prepare_raw_data.py       # é˜¶æ®µ1: å‡†å¤‡åŸå§‹æ•°æ®ï¼ˆDianJin-R1-Data + è‡ªå®šä¹‰ï¼‰
â”‚   â”œâ”€â”€ 2_distill_data.py           # é˜¶æ®µ2: Teacher æ¨¡å‹è’¸é¦ç”Ÿæˆ CoT
â”‚   â”œâ”€â”€ 3_filter_data.py            # é˜¶æ®µ3: è§„åˆ™ + Judge åŒé‡è¿‡æ»¤
â”‚   â”œâ”€â”€ 4_train_sft.py              # é˜¶æ®µ4: SFT ç›‘ç£å¾®è°ƒï¼ˆå­¦æ ¼å¼ï¼‰
â”‚   â”œâ”€â”€ 5_train_grpo.py             # é˜¶æ®µ5: GRPO å¼ºåŒ–å­¦ä¹ ï¼ˆæå‡†ç¡®ç‡ï¼‰
â”‚   â”œâ”€â”€ 6_evaluate.py               # é˜¶æ®µ6: Base æ¨ç† + Judge åˆ¤åˆ†
â”‚   â”œâ”€â”€ 7_deploy.py                 # é˜¶æ®µ7: LoRA åˆå¹¶ + vLLM éƒ¨ç½²
â”‚   â””â”€â”€ 8_ablation_study.py         # é˜¶æ®µ8: æ¶ˆèå®éªŒå¯¹æ¯”
â”‚
â”œâ”€â”€ docs/                           # æ–‡æ¡£ç›®å½•
â”‚   â””â”€â”€ wandb_integration.md        # Wandb é›†æˆè¯´æ˜
â”‚
â”œâ”€â”€ dataraw/                        # åŸå§‹æ•°æ®ç›®å½•
â”‚   â””â”€â”€ raw.jsonl                   # åŸå§‹é—®ç­”æ•°æ®
â”‚
â”œâ”€â”€ dataprocessed/                  # å¤„ç†åæ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ distilled.jsonl             # è’¸é¦åæ•°æ®ï¼ˆå« CoTï¼‰
â”‚   â”œâ”€â”€ sft.jsonl                   # SFT è®­ç»ƒæ•°æ®
â”‚   â”œâ”€â”€ rl.jsonl                    # RL è®­ç»ƒæ•°æ®
â”‚   â”œâ”€â”€ test.jsonl                  # æµ‹è¯•æ•°æ®
â”‚   â””â”€â”€ filter_stats.json           # è¿‡æ»¤ç»Ÿè®¡
â”‚
â”œâ”€â”€ ckpts/                          # æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ sft_lora/                   # SFT LoRA æƒé‡
â”‚   â”œâ”€â”€ grpo_lora/                  # GRPO LoRA æƒé‡
â”‚   â””â”€â”€ merged_model/               # åˆå¹¶åå®Œæ•´æ¨¡å‹
â”‚
â”œâ”€â”€ reports/                        # è¯„æµ‹æŠ¥å‘Š
â”‚   â”œâ”€â”€ eval_*.json                 # è¯„æµ‹æ‘˜è¦
â”‚   â”œâ”€â”€ eval_details_*.jsonl        # è¯„æµ‹è¯¦æƒ…
â”‚   â””â”€â”€ ablation_summary_*.json     # æ¶ˆèå®éªŒæŠ¥å‘Š
â”‚
â””â”€â”€ logs/                           # è®­ç»ƒæ—¥å¿—
    â”œâ”€â”€ sft_train.log
    â””â”€â”€ grpo_train.log
```

---

## ç¯å¢ƒé…ç½®

### ç¡¬ä»¶è¦æ±‚

| é˜¶æ®µ                | æœ€ä½é…ç½®      | æ¨èé…ç½®               |
| ------------------- | ------------- | ---------------------- |
| æ•°æ®å‡†å¤‡            | CPU + 8GB RAM | -                      |
| æ•°æ®è’¸é¦ï¼ˆTeacherï¼‰ | 8GB VRAM      | 16GB+ VRAM             |
| åŒé‡è¿‡æ»¤ï¼ˆJudgeï¼‰   | 8GB VRAM      | 16GB+ VRAM             |
| SFT/GRPO è®­ç»ƒ       | 16GB VRAM     | 24GB+ VRAM (5090/A100) |
| è¯„æµ‹/éƒ¨ç½²           | 8GB VRAM      | 16GB+ VRAM             |

### å®‰è£…ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
conda create -n ftmodel python=3.10
conda activate ftmodel

# å®‰è£…ä¾èµ–
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# å¦‚æœåœ¨ AutoDL ç­‰äº‘å¹³å°ï¼Œå¯èƒ½éœ€è¦é¢å¤–å®‰è£…
pip install flash-attn --no-build-isolation
```

### é…ç½® Wandbï¼ˆå¯é€‰ï¼‰

é¡¹ç›®é›†æˆäº† Wandb ç”¨äºè®­ç»ƒç›‘æ§ï¼Œé¦–æ¬¡ä½¿ç”¨éœ€ç™»å½•ï¼š

```bash
# å®‰è£… wandb
pip install wandb

# ç™»å½•ï¼ˆä» https://wandb.ai/authorize è·å– API Keyï¼‰
wandb login
```

é…ç½®ä½äº `configs/config.py` çš„ `WandbConfig`ï¼Œå¯ç¦ç”¨ï¼š

```python
WANDB_CONFIG.enabled = False  # ç¦ç”¨ wandb
```

è¯¦è§ [docs/wandb_integration.md](docs/wandb_integration.md)

---

## æ‰§è¡Œæµç¨‹

### å®Œæ•´æµç¨‹å›¾

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ•°æ®å‡†å¤‡é˜¶æ®µ                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. å‡†å¤‡åŸå§‹æ•°æ®      â†’  2. Teacherè’¸é¦   â†’  3. è§„åˆ™+Judgeè¿‡æ»¤        â”‚
â”‚  (1_prepare_raw_data)   (2_distill_data)    (3_filter_data)          â”‚
â”‚       â†“                       â†“                    â†“                  â”‚
â”‚   raw.jsonl             distilled.jsonl     sft.jsonl + rl.jsonl     â”‚
â”‚                         (Teacherç”ŸæˆCoT)    (Judgeè¯„ä¼°æ¨ç†è´¨é‡)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ¨¡å‹è®­ç»ƒé˜¶æ®µ                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  4. SFT è®­ç»ƒ          â†’  5. GRPO è®­ç»ƒï¼ˆå« Judge è¯„åˆ†ï¼‰                 â”‚
â”‚  (4_train_sft)           (5_train_grpo)                              â”‚
â”‚       â†“                        â†“                                      â”‚
â”‚  ckpts/sft_lora/         ckpts/grpo_lora/                            â”‚
â”‚  (Baseå­¦ä¹ æ ¼å¼)           (Baseæå‡å‡†ç¡®ç‡)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     è¯„æµ‹ä¸éƒ¨ç½²é˜¶æ®µ                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  6. è¯„æµ‹(Judgeåˆ¤åˆ†)  â†’  7. éƒ¨ç½²(vLLM)  â†’  8. æ¶ˆèå®éªŒ                  â”‚
â”‚  (6_evaluate)           (7_deploy)        (8_ablation_study)         â”‚
â”‚       â†“                      â†“                   â†“                    â”‚
â”‚  reports/eval_*.json    OpenAI APIæœåŠ¡    reports/ablation_*.json    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### é˜¶æ®µ1: å‡†å¤‡åŸå§‹æ•°æ®

```bash
python scripts/1_prepare_raw_data.py
```

**åŠŸèƒ½**ï¼š

- ä¸‹è½½ DianJin-R1-Data æ•°æ®é›†ï¼ˆæ”¯æŒ ModelScope / HuggingFaceï¼‰
- æ·»åŠ è‡ªå®šä¹‰é‡‘èé—®ç­”æ•°æ®
- è‡ªåŠ¨åˆ†ç±»é¢˜ç›®ç±»å‹ï¼ˆè®¡ç®—é¢˜/æ¦‚å¿µé¢˜/åˆ†æé¢˜/æ¨ç†é¢˜ï¼‰
- åˆ†å±‚æŠ½æ ·ä¿è¯æ•°æ®åˆ†å¸ƒ

**è¾“å‡º**ï¼š`dataraw/raw.jsonl`

### é˜¶æ®µ2: æ•°æ®è’¸é¦

```bash
python scripts/2_distill_data.py
```

**åŠŸèƒ½**ï¼š

- ä½¿ç”¨æœ¬åœ° **Teacher æ¨¡å‹**ï¼ˆDeepSeek-R1-Distill-Qwen-7Bï¼‰ç”Ÿæˆ Chain-of-Thought
- å¼ºåˆ¶è¾“å‡º `<think>...</think><answer>...</answer>` æ ¼å¼
- 4bit é‡åŒ–åŠ è½½ï¼ŒèŠ‚çœæ˜¾å­˜
- å¢é‡ä¿å­˜é˜²æ­¢ä¸­æ–­ä¸¢å¤±

**è¾“å‡º**ï¼š`dataprocessed/distilled.jsonl`

### é˜¶æ®µ3: åŒé‡è¿‡æ»¤

```bash
python scripts/3_filter_data.py
```

**åŠŸèƒ½**ï¼š

- **ç¬¬ä¸€å±‚ï¼ˆè§„åˆ™è¿‡æ»¤ï¼‰**ï¼š
  - æ ¼å¼æ£€æŸ¥ï¼ˆæ ‡ç­¾å®Œæ•´æ€§å’Œé¡ºåºï¼‰
  - ç­”æ¡ˆæ­£ç¡®æ€§ï¼ˆæ•°å€¼åŒ¹é…/å…³é”®è¯åŒ¹é…ï¼‰
- **ç¬¬äºŒå±‚ï¼ˆJudge è¿‡æ»¤ï¼‰**ï¼š
  - ä½¿ç”¨ **Judge æ¨¡å‹**ï¼ˆQwen2.5-7B-Instructï¼‰è¯„ä¼°æ¨ç†è´¨é‡
  - å¤šç»´åº¦æ‰“åˆ†ï¼šé€»è¾‘æ¸…æ™°åº¦ã€ä¸“ä¸šå‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€ç®€æ´æ€§
- è‡ªåŠ¨åˆ‡åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†ï¼ˆ8:2ï¼‰

**è¾“å‡º**ï¼š

- `dataprocessed/sft.jsonl` - SFT è®­ç»ƒæ•°æ®
- `dataprocessed/rl.jsonl` - RL è®­ç»ƒæ•°æ®
- `dataprocessed/test.jsonl` - æµ‹è¯•æ•°æ®
- `dataprocessed/filter_stats.json` - è¿‡æ»¤ç»Ÿè®¡

### é˜¶æ®µ4: SFT è®­ç»ƒ

```bash
python scripts/4_train_sft.py
```

**åŠŸèƒ½**ï¼š

- 4bit é‡åŒ–åŠ è½½ **Base æ¨¡å‹**ï¼ˆQwen2.5-1.5B-Instructï¼‰
- LoRA å¾®è°ƒï¼ˆr=16, alpha=32ï¼‰
- Qwen chat template æ ¼å¼åŒ–
- æ¢¯åº¦æ£€æŸ¥ç‚¹èŠ‚çœæ˜¾å­˜
- Wandb å®æ—¶ç›‘æ§ï¼ˆå¯é€‰ï¼‰

**æ ¸å¿ƒå‚æ•°**ï¼ˆå¯åœ¨ `configs/config.py` è°ƒæ•´ï¼‰ï¼š

```python
SFT_CONFIG.num_train_epochs = 2
SFT_CONFIG.per_device_train_batch_size = 2
SFT_CONFIG.gradient_accumulation_steps = 8
SFT_CONFIG.learning_rate = 2e-4
```

**è¾“å‡º**ï¼š`ckpts/sft_lora/`

### é˜¶æ®µ5: GRPO è®­ç»ƒ

```bash
# å®Œæ•´æ¨¡å¼ï¼ˆä½¿ç”¨ Judge æ¨¡å‹è¯„åˆ†ï¼‰
python scripts/5_train_grpo.py

# ç®€åŒ–æ¨¡å¼ï¼ˆä»…è§„åˆ™è¯„åˆ†ï¼‰
python scripts/5_train_grpo.py --no-judge
```

**åŠŸèƒ½**ï¼š

- åŸºäº SFT æ¨¡å‹ç»§ç»­è®­ç»ƒ
- **æ ¼å¼å¥–åŠ±**ï¼ˆ0.3æƒé‡ï¼‰ï¼šè§„åˆ™æ£€æŸ¥ `<think><answer>` æ ‡ç­¾
- **å‡†ç¡®æ€§å¥–åŠ±**ï¼ˆ0.7æƒé‡ï¼‰ï¼š
  - è§„åˆ™åŒ¹é…ï¼šæ•°å€¼/å…³é”®è¯åŒ¹é…
  - Judge è¯„åˆ†ï¼š**Judge æ¨¡å‹**ç»¼åˆè¯„ä¼°ï¼ˆå¯é€‰ï¼‰
- KL æ•£åº¦çº¦æŸé˜²æ­¢åç¦»

**æ ¸å¿ƒå‚æ•°**ï¼š

```python
GRPO_CONFIG.num_sample_generations = 4  # æ¯ä¸ª prompt é‡‡æ ·æ•°
GRPO_CONFIG.temperature = 0.7
GRPO_CONFIG.kl_coef = 0.05
GRPO_CONFIG.format_reward_weight = 0.3
GRPO_CONFIG.accuracy_reward_weight = 0.7
```

**è¾“å‡º**ï¼š`ckpts/grpo_lora/`

### é˜¶æ®µ6: è¯„æµ‹

```bash
# è¯„æµ‹ GRPO æ¨¡å‹ï¼ˆé»˜è®¤ï¼‰+ Judge åˆ¤åˆ†
python scripts/6_evaluate.py

# è¯„æµ‹ SFT æ¨¡å‹
python scripts/6_evaluate.py --eval_sft

# ä»…è§„åˆ™è¯„æµ‹ï¼ˆä¸ä½¿ç”¨ Judgeï¼‰
python scripts/6_evaluate.py --no-judge

# ä½¿ç”¨ vLLM åŠ é€Ÿï¼ˆéœ€è¦å…ˆåˆå¹¶æ¨¡å‹ï¼‰
python scripts/6_evaluate.py --use_vllm --model_path ckpts/merged_model
```

**è¯„æµ‹æŒ‡æ ‡**ï¼š

- æ ¼å¼æ­£ç¡®ç‡ï¼š`<think><answer>` ç»“æ„å®Œæ•´
- ç­”æ¡ˆæ­£ç¡®ç‡ï¼šæ•°å€¼é¢˜ç²¾ç¡®åŒ¹é…ï¼ŒQAé¢˜å…³é”®è¯åŒ¹é…
- Judge åˆ¤åˆ†ï¼šæ¨ç†è´¨é‡ç»¼åˆè¯„ä¼°
- æŒ‰é¢˜ç›®ç±»å‹ç»†åˆ†ç»Ÿè®¡

**è¾“å‡º**ï¼š`reports/eval_*.json`

### é˜¶æ®µ7: éƒ¨ç½²

```bash
# 1. åˆå¹¶ LoRA æƒé‡åˆ° Base æ¨¡å‹
python scripts/7_deploy.py --action merge

# 2. å¯åŠ¨ vLLM OpenAI-compatible API æœåŠ¡
python scripts/7_deploy.py --action serve

# 3. æµ‹è¯•æœåŠ¡
python scripts/7_deploy.py --action test

# æˆ–ä½¿ç”¨ç®€æ˜“ Flask æœåŠ¡ï¼ˆä¸éœ€è¦ vLLMï¼‰
python scripts/7_deploy.py --action simple
```

**API è°ƒç”¨ç¤ºä¾‹**ï¼š

```bash
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "ckpts/merged_model",
    "messages": [{"role": "user", "content": "æŸå…¬å¸2023å¹´è¥æ”¶1000ä¸‡å…ƒï¼ŒåŒæ¯”å¢é•¿25%ï¼Œè¯·è®¡ç®—2022å¹´è¥æ”¶ã€‚"}]
  }'
```

### é˜¶æ®µ8: æ¶ˆèå®éªŒ

```bash
python scripts/8_ablation_study.py
```

**å¯¹æ¯”å®éªŒ**ï¼š

1. **Base model only**ï¼ˆæ— è®­ç»ƒï¼‰- Qwen2.5-1.5B-Instruct åŸå§‹èƒ½åŠ›
2. **SFT only**ï¼ˆä»… SFTï¼‰- å­¦ä¹ è¾“å‡ºæ ¼å¼åçš„æ•ˆæœ
3. **SFT + GRPO**ï¼ˆå®Œæ•´æµç¨‹ï¼‰- å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–åçš„æ•ˆæœ

**è¾“å‡º**ï¼š`reports/ablation_summary_*.json`

---

## æ•°æ®æ ¼å¼è¯´æ˜

### åŸå§‹æ•°æ® (raw.jsonl)

```json
{
  "id": "dianjin_0",
  "question": "æŸå…¬å¸2023å¹´è¥æ”¶1000ä¸‡å…ƒï¼ŒåŒæ¯”å¢é•¿25%ï¼Œè¯·è®¡ç®—2022å¹´è¥æ”¶ã€‚",
  "gold_answer": "800",
  "type": "financial_calculation",
  "source": "dianjin-r1-data"
}
```

### è’¸é¦æ•°æ® (distilled.jsonl)

```json
{
  "id": "dianjin_0",
  "question": "...",
  "gold_answer": "800",
  "type": "financial_calculation",
  "teacher_output": "<think>\né¦–å…ˆï¼Œè®¾2022å¹´è¥æ”¶ä¸ºX...\n</think>\n<answer>\n800\n</answer>"
}
```

### SFT æ•°æ® (sft.jsonl)

```json
{
  "id": "dianjin_0",
  "prompt": "æŸå…¬å¸2023å¹´è¥æ”¶1000ä¸‡å…ƒï¼ŒåŒæ¯”å¢é•¿25%ï¼Œè¯·è®¡ç®—2022å¹´è¥æ”¶ã€‚",
  "response": "<think>...</think><answer>800</answer>",
  "type": "financial_calculation"
}
```

### RL æ•°æ® (rl.jsonl)

```json
{
  "id": "dianjin_0",
  "prompt": "æŸå…¬å¸2023å¹´è¥æ”¶1000ä¸‡å…ƒï¼ŒåŒæ¯”å¢é•¿25%ï¼Œè¯·è®¡ç®—2022å¹´è¥æ”¶ã€‚",
  "gold_answer": "800",
  "type": "financial_calculation"
}
```

---

## é…ç½®è¯´æ˜

ä¸»è¦é…ç½®åœ¨ `configs/config.py`ï¼š

```python
# ========== ä¸‰æ¨¡å‹æ¶æ„é…ç½® ==========
# Teacher æ¨¡å‹ï¼ˆç”¨äºè’¸é¦ï¼‰
TEACHER_CONFIG.model_name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"

# Judge æ¨¡å‹ï¼ˆç”¨äºè¿‡æ»¤ã€è¯„åˆ†ã€è¯„æµ‹ï¼‰
JUDGE_CONFIG.model_name = "Qwen/Qwen2.5-7B-Instruct"

# Base æ¨¡å‹ï¼ˆå¾…è®­ç»ƒçš„ç›®æ ‡å°æ¨¡å‹ï¼‰
MODEL_CONFIG.base_model = "Qwen/Qwen2.5-1.5B-Instruct"
MODEL_CONFIG.model_max_length = 2048

# ========== LoRA é…ç½® ==========
LORA_CONFIG.r = 16
LORA_CONFIG.lora_alpha = 32
LORA_CONFIG.target_modules = ["q_proj", "k_proj", "v_proj", "o_proj", ...]

# ========== SFT é…ç½® ==========
SFT_CONFIG.num_train_epochs = 2
SFT_CONFIG.learning_rate = 2e-4
SFT_CONFIG.per_device_train_batch_size = 2
SFT_CONFIG.gradient_accumulation_steps = 8

# ========== GRPO é…ç½® ==========
GRPO_CONFIG.format_reward_weight = 0.3
GRPO_CONFIG.accuracy_reward_weight = 0.7
GRPO_CONFIG.kl_coef = 0.05

# ========== Wandb é…ç½® ==========
WANDB_CONFIG.enabled = True
WANDB_CONFIG.project = "FTModel-Training"
```

---

## å¸¸è§é—®é¢˜

### Q1: æ˜¾å­˜ä¸è¶³ (OOM)

```python
# åœ¨ configs/config.py ä¸­è°ƒæ•´
SFT_CONFIG.per_device_train_batch_size = 1  # å‡å°
SFT_CONFIG.gradient_accumulation_steps = 16  # å¢å¤§
MODEL_CONFIG.model_max_length = 1024  # å‡å°
```

### Q2: Teacher/Judge æ¨¡å‹åŠ è½½å¤±è´¥

```bash
# æ£€æŸ¥æ¨¡å‹æ˜¯å¦ä¸‹è½½å®Œæˆ
# å¯ä»¥æ‰‹åŠ¨ä¸‹è½½åˆ°æœ¬åœ°ï¼Œç„¶åä¿®æ”¹ config.py ä¸­çš„æ¨¡å‹è·¯å¾„
TEACHER_CONFIG.model_name = "/path/to/local/DeepSeek-R1-Distill-Qwen-7B"
JUDGE_CONFIG.model_name = "/path/to/local/Qwen2.5-7B-Instruct"
```

### Q3: vLLM å¯åŠ¨å¤±è´¥

```bash
# æ£€æŸ¥æ˜¯å¦æ˜¯ LoRA adapter
# vLLM éœ€è¦åˆå¹¶åçš„å®Œæ•´æ¨¡å‹
python scripts/7_deploy.py --action merge
python scripts/7_deploy.py --action serve --model_path ckpts/merged_model
```

### Q4: æ¨¡å‹ä¸è¾“å‡ºæ­£ç¡®æ ¼å¼

- æ£€æŸ¥ SFT æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®
- å¢åŠ è®­ç»ƒæ­¥æ•°ï¼ˆè‡³å°‘ 500 æ­¥ï¼‰
- æ£€æŸ¥ chat template æ˜¯å¦æ­£ç¡®åº”ç”¨

### Q5: å¦‚ä½•è·³è¿‡ Judge æ¨¡å‹è¯„åˆ†ï¼Ÿ

```bash
# è¿‡æ»¤é˜¶æ®µï¼šä»…ä½¿ç”¨è§„åˆ™è¿‡æ»¤
python scripts/3_filter_data.py --no-judge

# GRPO é˜¶æ®µï¼šä»…ä½¿ç”¨è§„åˆ™å¥–åŠ±
python scripts/5_train_grpo.py --no-judge

# è¯„æµ‹é˜¶æ®µï¼šä»…ä½¿ç”¨è§„åˆ™è¯„æµ‹
python scripts/6_evaluate.py --no-judge
```

---

## é¢è¯•è¦ç‚¹

æœ¬é¡¹ç›®æ¶µç›–ä»¥ä¸‹é¢è¯•é«˜é¢‘è€ƒç‚¹ï¼š

### æ•°æ®å·¥ç¨‹

- **æ•°æ®è’¸é¦**ï¼šä¸ºä»€ä¹ˆç”¨ Teacher æ¨¡å‹ç”Ÿæˆ CoTï¼Ÿå°æ¨¡å‹ç¼ºä¹æ¨ç†èƒ½åŠ›
- **åŒé‡è¿‡æ»¤**ï¼šè§„åˆ™ä¿è¯æ ¼å¼ï¼ŒJudge ä¿è¯æ¨ç†è´¨é‡
- **åˆ†å±‚æŠ½æ ·**ï¼šä¿è¯æ•°æ®åˆ†å¸ƒåˆç†

### æ¨¡å‹è®­ç»ƒ

- **LoRA å¾®è°ƒ**ï¼šå‚æ•°é«˜æ•ˆï¼Œåªè®­ç»ƒçº¦ 0.1% çš„å‚æ•°
- **4bit é‡åŒ–**ï¼šNF4 + åŒé‡é‡åŒ–ï¼Œæ˜¾å­˜å ç”¨é™ä½ 4 å€
- **GRPO vs PPO**ï¼šGRPO ç”¨ç»„å†…ç›¸å¯¹è¡¨ç°è®¡ç®—ä¼˜åŠ¿ï¼Œæ— éœ€ value network

### å¥–åŠ±è®¾è®¡

- **æ ¼å¼å¥–åŠ±**ï¼šä¿è¯å¯è§£é‡Šæ€§
- **å‡†ç¡®æ€§å¥–åŠ±**ï¼šä¿è¯ä¸šåŠ¡ä»·å€¼
- **KL çº¦æŸ**ï¼šé˜²æ­¢ reward hacking

### éƒ¨ç½²ä¼˜åŒ–

- **vLLM**ï¼šPagedAttention + Continuous batching
- **æ¨¡å‹åˆå¹¶**ï¼šéƒ¨ç½²æ—¶å‡å°‘æ¨ç†å¼€é”€

---

## å‚è€ƒèµ„æ–™

- [Fin-R1 è®ºæ–‡](https://arxiv.org/abs/xxx)
- [TRL æ–‡æ¡£](https://huggingface.co/docs/trl)
- [vLLM æ–‡æ¡£](https://docs.vllm.ai)
- [PEFT æ–‡æ¡£](https://huggingface.co/docs/peft)
- [DeepSeek-R1 æ¨¡å‹](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B)
- [Qwen2.5 æ¨¡å‹ç³»åˆ—](https://huggingface.co/Qwen)
- [DianJin-R1-Data æ•°æ®é›†](https://huggingface.co/datasets/DianJin/DianJin-R1-Data)

---

## License

MIT License
