# RTX 5090 åŒ…å…¼å®¹æ€§æ£€æŸ¥æŠ¥å‘Š

ç”Ÿæˆæ—¶é—´: 2026-01-21

## æ›´æ–°åçš„ä¾èµ–åŒ…ç‰ˆæœ¬

### æ ¸å¿ƒæ¡†æ¶
- torch: 2.1.0 â†’ **2.7.0** (æ”¯æŒ CUDA 12.xï¼ŒRTX 5090 ä¼˜åŒ–)
- transformers: 4.45.0 â†’ **4.48.0**
- trl: 0.12.0 â†’ **0.14.0**
- peft: 0.13.0 â†’ **0.15.0**

### é‡åŒ–å’ŒåŠ é€Ÿ
- bitsandbytes: 0.44.0 â†’ **0.45.1**
- accelerate: 0.34.0 â†’ **1.2.1**

### éƒ¨ç½²
- vllm: 0.6.3 â†’ **0.6.6.post1**

### æ•°æ®å¤„ç†
- datasets: 2.20.0 â†’ **3.3.1** âš ï¸ **ä¸»è¦ç‰ˆæœ¬å‡çº§**

### å…¶ä»–å·¥å…·
- pandas: 2.1.0 â†’ **2.2.3**
- openai: 1.35.0 â†’ **1.61.2**
- requests: 2.31.0 â†’ **2.32.3**
- tqdm: 4.66.0 â†’ **4.67.1**
- wandb: (æœªæŒ‡å®š) â†’ **>=0.19.1**
- sentencepiece: 0.2.0 (ä¿æŒä¸å˜)
- protobuf: 4.25.0 â†’ **5.29.3**

---

## è„šæœ¬å¯¼å…¥åˆ†æ

### 1. scripts/1_prepare_raw_data.py
**å¯¼å…¥çš„åŒ…:**
- `datasets` (load_dataset)
- `json`, `os`, `sys`, `pathlib`

**æ½œåœ¨é—®é¢˜:**
- âš ï¸ `datasets` ä» 2.20.0 å‡çº§åˆ° 3.3.1 (ä¸»è¦ç‰ˆæœ¬å‡çº§)
- `load_dataset` API åœ¨ 3.x ä¸­å¯èƒ½æœ‰å˜åŒ–

**å»ºè®®:**
- æµ‹è¯• `load_dataset` å‡½æ•°æ˜¯å¦æ­£å¸¸å·¥ä½œ
- æ£€æŸ¥ split å‚æ•°è¯­æ³•æ˜¯å¦å˜åŒ–

---

### 2. scripts/2_distill_data.py
**å¯¼å…¥çš„åŒ…:**
- `transformers` (AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig)
- `torch`
- `json`, `os`, `sys`, `pathlib`, `tqdm`

**æ½œåœ¨é—®é¢˜:**
- âœ“ æ‰€æœ‰å¯¼å…¥åº”è¯¥å‘åå…¼å®¹
- BitsAndBytesConfig åœ¨æ–°ç‰ˆ transformers ä¸­ä¿æŒç¨³å®š

---

### 3. scripts/3_filter_data.py
**å¯¼å…¥çš„åŒ…:**
- `transformers` (AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig)
- `torch`
- `json`, `os`, `sys`, `re`, `pathlib`, `tqdm`

**æ½œåœ¨é—®é¢˜:**
- âœ“ æ‰€æœ‰å¯¼å…¥åº”è¯¥å‘åå…¼å®¹

---

### 4. scripts/4_train_sft.py âš ï¸ **å…³é”®æ£€æŸ¥**
**å¯¼å…¥çš„åŒ…:**
- `torch`
- `datasets` (Dataset)
- `transformers` (AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments)
- `peft` (LoraConfig, get_peft_model, prepare_model_for_kbit_training)
- `trl` (SFTTrainer, SFTConfig)

**æ½œåœ¨é—®é¢˜:**
- âš ï¸ **trl 0.14.0**: `SFTConfig` å’Œ `SFTTrainer` API å¯èƒ½æœ‰å˜åŒ–
  - ç¬¬ 205-226 è¡Œ: `SFTConfig` å‚æ•°æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
  - ç¬¬ 229-234 è¡Œ: `SFTTrainer` åˆå§‹åŒ–å‚æ•°
- âš ï¸ **datasets 3.3.1**: `Dataset.from_list()` æ˜¯å¦ä¿æŒå…¼å®¹

**éœ€è¦éªŒè¯çš„ä»£ç ä½ç½®:**
```python
# ç¬¬ 205 è¡Œ
training_args = SFTConfig(
    output_dir=SFT_CONFIG.output_dir,
    # ... å…¶ä»–å‚æ•°
    dataset_text_field="text",  # æ£€æŸ¥æ­¤å‚æ•°æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
)

# ç¬¬ 229 è¡Œ
trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset,
    tokenizer=tokenizer,  # æ³¨æ„ï¼šå¯èƒ½éœ€è¦æ”¹ä¸º processing_class
)
```

---

### 5. scripts/5_train_grpo.py âš ï¸ **å…³é”®æ£€æŸ¥**
**å¯¼å…¥çš„åŒ…:**
- `torch`
- `datasets` (Dataset)
- `transformers` (AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig)
- `peft` (PeftModel)
- `trl` (GRPOConfig, GRPOTrainer)

**æ½œåœ¨é—®é¢˜:**
- âš ï¸ **trl 0.14.0**: `GRPOConfig` å’Œ `GRPOTrainer` API å¯èƒ½æœ‰å˜åŒ–
  - ç¬¬ 525-543 è¡Œ: `GRPOConfig` å‚æ•°æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
  - ç¬¬ 552-558 è¡Œ: `GRPOTrainer` åˆå§‹åŒ–å‚æ•°
  - **ç¬¬ 556 è¡Œ**: `processing_class=tokenizer` å‚æ•°åç§°æ˜¯å¦æ­£ç¡®

**éœ€è¦éªŒè¯çš„ä»£ç ä½ç½®:**
```python
# ç¬¬ 525 è¡Œ
grpo_config = GRPOConfig(
    output_dir=GRPO_CONFIG.output_dir,
    num_generations=GRPO_CONFIG.num_sample_generations,  # æ£€æŸ¥å‚æ•°å
    max_completion_length=GRPO_CONFIG.response_length,  # æ£€æŸ¥å‚æ•°å
    # ...
)

# ç¬¬ 552 è¡Œ
trainer = GRPOTrainer(
    model=model,
    args=grpo_config,
    train_dataset=formatted_dataset,
    processing_class=tokenizer,  # âš ï¸ æ–°ç‰ˆæœ¬å¯èƒ½æ˜¯ tokenizer è€Œé processing_class
    reward_funcs=reward_fn,
)
```

---

### 6. scripts/6_evaluate.py
**å¯¼å…¥çš„åŒ…:**
- `torch`
- `transformers` (AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig)
- `peft` (PeftModel)
- `vllm` (LLM, SamplingParams)
- `tqdm`, `json`, `os`, `sys`, `re`, `pathlib`, `datetime`

**æ½œåœ¨é—®é¢˜:**
- âš ï¸ **vllm 0.6.6.post1**: API å¯èƒ½æœ‰å°çš„å˜åŒ–
- ç¬¬ 325 è¡Œå’Œç¬¬ 397 è¡Œä½¿ç”¨ vllmï¼Œéœ€è¦æµ‹è¯•

---

### 7. scripts/7_deploy.py
**å¯¼å…¥çš„åŒ…:**
- `torch`
- `transformers` (AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig)
- `peft` (PeftModel)
- `vllm` (éœ€è¦æ—¶å¯¼å…¥)
- `subprocess`, `requests`, `time`

**æ½œåœ¨é—®é¢˜:**
- âš ï¸ **vllm 0.6.6.post1**: å¯åŠ¨å‘½ä»¤å¯èƒ½æœ‰å˜åŒ–
- ç¬¬ 124-132 è¡Œ: vLLM å¯åŠ¨å‚æ•°éœ€è¦éªŒè¯

---

## å…³é”®å…¼å®¹æ€§é—®é¢˜æ€»ç»“

### ğŸ”´ **é«˜ä¼˜å…ˆçº§** - éœ€è¦ç«‹å³æ£€æŸ¥

1. **trl SFTTrainer å‚æ•°å˜åŒ– (scripts/4_train_sft.py)**
   - æ£€æŸ¥ `tokenizer` å‚æ•°æ˜¯å¦åº”è¯¥æ”¹ä¸º `processing_class`
   - æ£€æŸ¥ `SFTConfig` çš„ `dataset_text_field` å‚æ•°æ˜¯å¦ä»ç„¶æœ‰æ•ˆ

2. **trl GRPOTrainer å‚æ•°å˜åŒ– (scripts/5_train_grpo.py)**
   - éªŒè¯ `processing_class=tokenizer` æ˜¯å¦æ­£ç¡®
   - éªŒè¯ `GRPOConfig` çš„å‚æ•°åç§° (`num_generations`, `max_completion_length`)

3. **datasets ä¸»è¦ç‰ˆæœ¬å‡çº§ (scripts/1_prepare_raw_data.py)**
   - æµ‹è¯• `load_dataset` çš„ split è¯­æ³•
   - æµ‹è¯• `Dataset.from_list()` æ˜¯å¦æ­£å¸¸å·¥ä½œ

### ğŸŸ¡ **ä¸­ä¼˜å…ˆçº§** - å»ºè®®æµ‹è¯•

4. **vllm API å˜åŒ– (scripts/6_evaluate.py, scripts/7_deploy.py)**
   - æµ‹è¯• vLLM çš„ LLM åˆå§‹åŒ–å‚æ•°
   - æµ‹è¯• vLLM å¯åŠ¨æœåŠ¡çš„å‘½ä»¤è¡Œå‚æ•°

5. **transformers BitsAndBytesConfig (æ‰€æœ‰è®­ç»ƒè„šæœ¬)**
   - éªŒè¯é‡åŒ–é…ç½®å‚æ•°æ˜¯å¦å…¼å®¹

### âœ… **ä½ä¼˜å…ˆçº§** - åº”è¯¥å…¼å®¹

6. **å…¶ä»–åŒ…**: pandas, openai, requests, tqdm, wandb, protobuf
   - è¿™äº›åŒ…çš„å‡çº§åº”è¯¥å‘åå…¼å®¹

---

## æ¨èçš„éªŒè¯æ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šå®‰è£…æ–°ç‰ˆæœ¬ä¾èµ–
```bash
pip install -r requirements.txt
```

### ç¬¬äºŒæ­¥ï¼šè¿è¡Œç®€å•çš„å¯¼å…¥æµ‹è¯•
```bash
python -c "from trl import SFTTrainer, SFTConfig, GRPOConfig, GRPOTrainer; print('TRL import OK')"
python -c "from datasets import Dataset, load_dataset; print('Datasets import OK')"
python -c "from vllm import LLM, SamplingParams; print('vLLM import OK')"
```

### ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥ TRL å‚æ•°å…¼å®¹æ€§
åˆ›å»ºæµ‹è¯•è„šæœ¬æ£€æŸ¥ `SFTTrainer` å’Œ `GRPOTrainer` çš„å‚æ•°ç­¾åï¼š
```python
import inspect
from trl import SFTTrainer, GRPOTrainer

# æ£€æŸ¥ SFTTrainer å‚æ•°
print("SFTTrainer parameters:")
print(inspect.signature(SFTTrainer.__init__))

# æ£€æŸ¥ GRPOTrainer å‚æ•°
print("\nGRPOTrainer parameters:")
print(inspect.signature(GRPOTrainer.__init__))
```

### ç¬¬å››æ­¥ï¼šè¿è¡Œå•å…ƒæµ‹è¯•
åœ¨è¿è¡Œå®Œæ•´è®­ç»ƒå‰ï¼Œæµ‹è¯•æ¯ä¸ªè„šæœ¬çš„æ ¸å¿ƒåŠŸèƒ½ã€‚

---

## å¯èƒ½éœ€è¦çš„ä»£ç ä¿®æ”¹

### å¦‚æœ SFTTrainer å‚æ•°å˜åŒ–ï¼š
```python
# æ—§ç‰ˆæœ¬ (å¯èƒ½)
trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset,
    tokenizer=tokenizer,  # æ—§å‚æ•°å
)

# æ–°ç‰ˆæœ¬ (å¯èƒ½éœ€è¦)
trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset,
    processing_class=tokenizer,  # æ–°å‚æ•°å
)
```

### å¦‚æœ GRPOTrainer å‚æ•°å˜åŒ–ï¼š
```python
# å½“å‰ä»£ç 
trainer = GRPOTrainer(
    model=model,
    args=grpo_config,
    train_dataset=formatted_dataset,
    processing_class=tokenizer,  # æ£€æŸ¥è¿™ä¸ªå‚æ•°å
    reward_funcs=reward_fn,
)
```

---

## ç»“è®º

æ€»ä½“æ¥è¯´ï¼Œå¤§éƒ¨åˆ†ä¾èµ–åŒ…çš„å‡çº§åº”è¯¥æ˜¯å‘åå…¼å®¹çš„ã€‚ä¸»è¦éœ€è¦å…³æ³¨çš„æ˜¯ï¼š

1. **datasets 3.x çš„ä¸»è¦ç‰ˆæœ¬å‡çº§** - éœ€è¦æµ‹è¯•
2. **trl 0.14.0 çš„ API å˜åŒ–** - éœ€è¦éªŒè¯å‚æ•°åç§°
3. **vllm çš„å°ç‰ˆæœ¬å‡çº§** - éœ€è¦æµ‹è¯•æœåŠ¡å¯åŠ¨

å»ºè®®åœ¨å®Œæ•´è®­ç»ƒå‰ï¼š
1. å…ˆè¿›è¡Œå¯¼å…¥æµ‹è¯•
2. æ£€æŸ¥ API å‚æ•°ç­¾å
3. è¿è¡Œå°è§„æ¨¡æµ‹è¯•ç¡®ä¿å…¼å®¹æ€§
4. å†è¿›è¡Œå®Œæ•´è®­ç»ƒ

å¦‚æœé‡åˆ°å…¼å®¹æ€§é—®é¢˜ï¼Œå¯ä»¥è€ƒè™‘ï¼š
- é™çº§æŸäº›åŒ…åˆ°ä¸­é—´ç‰ˆæœ¬
- ä¿®æ”¹ä»£ç ä»¥é€‚é…æ–° API
- æŸ¥çœ‹å¯¹åº”åŒ…çš„ changelog å’Œ migration guide
